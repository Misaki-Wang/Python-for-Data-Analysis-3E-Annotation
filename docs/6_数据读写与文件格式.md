数据读取的分类：

- 磁盘存储格式读取，如文本文件、二进制文件
- 数据库数据加载
- 网络资源交互，Web API

# 读写文本格式的数据

Pandas常用的加载函数：

![表6-1 pandas中的解析函数](http://upload-images.jianshu.io/upload_images/7178691-958f849e6067b19b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

加载函数常用参数说明：

- 索引：将一个或多个列当做返回的DataFrame处理，以及是否从文件、用户获取列名。
- 类型推断和数据转换：包括用户定义值的转换、和自定义的缺失值标记列表等。
- 日期解析：包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列。
- 迭代：支持对大文件进行逐块迭代。
- 不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西（比如由成千上万个逗号隔开的数值数据）。

`read_csv`使用最多，参数说明：

![](http://upload-images.jianshu.io/upload_images/7178691-082daf4a00ed9494.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](http://upload-images.jianshu.io/upload_images/7178691-f2bcc0a703c7236f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![](http://upload-images.jianshu.io/upload_images/7178691-597327ade3e94c7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 逐块读取文本文件

对于大文件，只读取其中一部分或逐块进行迭代，有效避免爆内存

通过`pd.options.display.max_rows = 10`使数据显示更紧凑

`pd.read_csv("filename",nrows = 5)`使数据显示前5行

`pd.read_csv("filename",chunksize = 1000)`指定每块读取行数

```python
chunker = pd.read_csv("filename",chunksize = 1e3)

#用for循环进行逐块读取
for piece in chunker:		
    ........
    
#或者用next方法
chunk1 = next(chunker)
chunk2 = next(chunker)
```

`get_chunk` 

```python
In [218]: with pd.read_csv("tmp.csv", sep="|", iterator=True) as reader: #注意iterator设置
   .....:     reader.get_chunk(5) #读取接下来5行数据
   .....: 
```

<img src="https://picgo-wbyz.oss-cn-nanjing.aliyuncs.com/202307181312498.png" alt="image-20230718131257466" style="zoom: 67%;" />

[(62条消息) Python chunk读取超大文件_get_chunk_w55100的博客-CSDN博客](https://blog.csdn.net/w55100/article/details/90111254)



```python
#通过一下方法估测读取次数和划分块数
count = 0
fp = open('filename','r', encoding='utf-8')
while 1:
	buffer = fp.read(8*1024*1024)
	if not buffer:
		break
	count += buffer.count('\n')
 
print(count)
fp.close()
 
 
#https://blog.csdn.net/u012762054/article/details/78384294
```



## 将数据写入文本格式

`to_csv()`导出到文件

```python
pd.to_csv("filename",
         sep = "|",		 				 #默认分隔符为,
         na_rep= "NULL"，				#默认值为空字符串
         index = False,header = False,	#默认输出行和列的标签
         columns = []					#只输出列的一部分，且可以指定顺序
         )
```



## 使用其他分隔符格式

单分隔符文件读取，Python内置的csv模块：

```python
import csv
f = open("filename") #打开文件
lines = list(csv.reader(f)) #读取为列表
header,lines = lines[0],lines[1:] # 表头，数据划分
data_dict = {h:v for h,v in zip(header,zip(*valuse))} #创建字典
```



csv文件格式的定义

1. `csv.Dialect`子类定义

   ```python
   class my_dialect(csv.Dialect):
       ....
   ```

   ![](http://upload-images.jianshu.io/upload_images/7178691-7a1cee622459072b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

2. `csv.reader`关键字定义

   ```python
   reader = csv.reader("filename",delimiter = "|")
   ```



`csv.writer`手动输出分隔符文件，与`csv.reader`语法和参数类似

## JSON数据

Python中的处理
`json.loads` `json.dumps`

Pandas中的处理
`pd.read_json` `pd.to_json` 

## XML HTML：网络抓取

`pd.read_html` `pd.read_xml`

# 二进制数据格式

## Excel读写

`conda install openpyxl ` `conda install xlrd`

Excel读取

- `pd.ExcelFile` 类

  ```python
  xlsx = pd.ExcelFile("filename")
  xlsx.parse(sheet_name="name",index_col=0) #使用parse读取到df中，并制定索引列
  ```

- `pd.read_excel`方法

  ```python
  df1 = pd.read_excel("filename")
  ```

Excel写入

- `pd.ExcelWriter`类
- `pd.to_excel`类

## HDF5格式

HDF5格式适合 “一次写多次读”的数据集

`conda install pytables`

`pd.HDFStore`类来处理

- 有`fixed`和`table`两种存储格式，
  `fixed`为默认值，`table`更慢但支持特殊语法查询

`pd.read_hdf`读取

# 与Web API交互

`conda install requests` 

# 与数据库交互

`conda install sqlalchemy` 

